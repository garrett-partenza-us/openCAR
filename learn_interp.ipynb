{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "93fd8d89-6f20-426c-897d-c4879d33dacd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "torch.set_printoptions(sci_mode=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 300,
   "id": "4f3a8277-ae1c-4a03-9881-688419ad7cd6",
   "metadata": {},
   "outputs": [],
   "source": [
    "image = torch.rand((5,5,1))\n",
    "image3c = torch.rand((5,5,3))\n",
    "x, y = torch.tensor(0.5), torch.tensor(0.5)\n",
    "x_b, y_b = torch.tensor(0.5).repeat(16).reshape(16,1), torch.tensor(0.5).repeat(16).reshape(16,1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 313,
   "id": "a51d8375-178a-4430-8c62-fe02c6b798ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "def compare():\n",
    "    bi = torch.Tensor(tuple(bilinear_interpolate(image3c[:,:,c], x, y).item() for c in range(3))).repeat(16)\n",
    "    bmm = matrix_interpolation_3cb(image3c, x_b, y_b).flatten()\n",
    "    return torch.isclose(bi,bmm).all().item()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "357ab016-5d30-48d9-ae9d-b7072d68f25c",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bilinear_interpolate(im, x, y, dtype=torch.FloatTensor, dtype_long=torch.LongTensor):\n",
    "    # Get four corner indicies\n",
    "    x0 = torch.floor(x).type(dtype_long)\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(y).type(dtype_long)\n",
    "    y1 = y0 + 1\n",
    "    # Clamp within h, w boundries\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1]-1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1]-1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0]-1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0]-1)\n",
    "    # Get four corner pixel values\n",
    "    Ia = im[x0, y0]\n",
    "    Ib = im[x0, y1]\n",
    "    Ic = im[x1, y0]\n",
    "    Id = im[x1, y1]\n",
    "    # Weight four corner pixel values\n",
    "    wa = (x1.type(dtype)-x) * (y1.type(dtype)-y)\n",
    "    wc = (x1.type(dtype)-x) * (y-y0.type(dtype))\n",
    "    wb = (x-x0.type(dtype)) * (y1.type(dtype)-y)\n",
    "    wd = (x-x0.type(dtype)) * (y-y0.type(dtype))\n",
    "    return torch.t((torch.t(Ia)*wa)) + torch.t(torch.t(Ib)*wb) + torch.t(torch.t(Ic)*wc) + torch.t(torch.t(Id)*wd)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "e7e7469b-d02d-43c7-a311-d584a04f6567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_interpolation(im, x, y, dtype=torch.FloatTensor, dtype_long=torch.LongTensor):\n",
    "    # Get four corner indicies\n",
    "    x0 = torch.floor(x).type(dtype_long)\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(y).type(dtype_long)\n",
    "    y1 = y0 + 1\n",
    "    # Clamp within h, w boundries\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1]-1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1]-1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0]-1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0]-1)\n",
    "    # Get four corner pixel values\n",
    "    Ia = im[x0, y0]\n",
    "    Ib = im[x0, y1]\n",
    "    Ic = im[x1, y0]\n",
    "    Id = im[x1, y1]\n",
    "    # Define matricies\n",
    "    scale = 1 / ( (x1-x0) * (y1-y0) )\n",
    "    m1 = torch.Tensor([x1-x, x-x0])\n",
    "    m2 = torch.Tensor([\n",
    "        [Ib, Ia],\n",
    "        [Id, Ic]\n",
    "    ])\n",
    "    m3 = torch.Tensor([\n",
    "        [y1-y],\n",
    "        [y-y0]\n",
    "    ])\n",
    "    return scale * torch.matmul( torch.matmul(m1, m2), m3 )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "32c9584b-e28d-4c16-b476-5201192a61f3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 35.4 ms, sys: 1e+03 Âµs, total: 36.4 ms\n",
      "Wall time: 64.2 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    res = bilinear_interpolate(image, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "041a97d6-9153-4a2c-8bb4-35db9a3c1109",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 31.9 ms, sys: 4.7 ms, total: 36.6 ms\n",
      "Wall time: 50.7 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    res = matrix_interpolation(image, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "6ac10e9b-e62c-470c-8095-f1fb07d4cd68",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_interpolation_3c(im, x, y, dtype=torch.FloatTensor, dtype_long=torch.LongTensor):\n",
    "    # Get four corner indicies\n",
    "    x0 = torch.floor(x).type(dtype_long)\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(y).type(dtype_long)\n",
    "    y1 = y0 + 1\n",
    "    # Clamp within h, w boundries\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1]-1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1]-1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0]-1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0]-1)\n",
    "    # Get four corner pixel values\n",
    "    Ia = im[x0, y0]\n",
    "    Ib = im[x0, y1]\n",
    "    Ic = im[x1, y0]\n",
    "    Id = im[x1, y1]\n",
    "    # Define matricies\n",
    "    scale = 1 / ( (x1-x0) * (y1-y0) )\n",
    "    m1 = torch.Tensor([x1-x, x-x0])\n",
    "    m2 = torch.cat([Ib, Ia, Id, Ic]).reshape(2,2,3)\n",
    "    m3 = torch.Tensor([\n",
    "        [y1-y],\n",
    "        [y-y0]\n",
    "    ])\n",
    "    return scale * torch.matmul( torch.matmul(m1, m2).t(), m3 ).t()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 251,
   "id": "e956dea3-d188-4e0f-9213-c13f0e5b7af5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 99.4 ms, sys: 2.91 ms, total: 102 ms\n",
      "Wall time: 263 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    for c in range(3):\n",
    "        res = matrix_interpolation(image3c[:,:,c], x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 252,
   "id": "4b7f43e7-499c-4bd7-9a8e-157f221837bc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "CPU times: user 42.1 ms, sys: 4.72 ms, total: 46.9 ms\n",
      "Wall time: 193 ms\n"
     ]
    }
   ],
   "source": [
    "%%time\n",
    "for i in range(100):\n",
    "    res = matrix_interpolation_3c(image3c, x, y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 337,
   "id": "09294452-96df-4e63-9b14-6f85683bf19f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def matrix_interpolation_3cb(im, x, y, dtype=torch.FloatTensor, dtype_long=torch.LongTensor):\n",
    "    # Get four corner indicies\n",
    "    x0 = torch.floor(x).type(dtype_long)\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(y).type(dtype_long)\n",
    "    y1 = y0 + 1\n",
    "    # Clamp within h, w boundries\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1]-1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1]-1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0]-1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0]-1)\n",
    "    # Get four corner pixel values\n",
    "    Ia = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x0, y0)])\n",
    "    Ib = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x0, y1)])\n",
    "    Ic = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x1, y0)])\n",
    "    Id = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x1, y1)])\n",
    "    # Define matricies\n",
    "    scale = (1 / ( (x1-x0) * (y1-y0) ) ).flatten()\n",
    "    m1 = torch.cat([ torch.sub(x1, x), torch.sub(x, x0)], dim=1)\n",
    "    m2 = torch.stack([Ib, Ia, Id, Ic], dim=1).reshape(16,2,2,3)\n",
    "    m3 = torch.cat([ torch.sub(y1, y), torch.sub(y, y0) ], dim=1)\n",
    "    # Reshape for batch matmul\n",
    "    m1 = m1.reshape(16,1,1,2).repeat(1,2,1,1)\n",
    "    m3 = m3.reshape(16,1,2,1)\n",
    "    return scale[:,None] * torch.matmul( torch.matmul(m1, m2).permute(0,3,2,1), m3 ).flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 338,
   "id": "d9073da5-986c-4fa9-8c17-4ad7b1b2502e",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479],\n",
       "        [0.7190, 0.4637, 0.7479]])"
      ]
     },
     "execution_count": 338,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "matrix_interpolation_3cb(image3c, x_b, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 339,
   "id": "36985ce3-1eef-46c2-ba69-c7cb4d5c82fb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 339,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "compare()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 351,
   "id": "f418eb71-e6fb-4dd3-8d6b-0abaa3440a61",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fast_interpolation_3cb(im, x, y, dtype=torch.FloatTensor, dtype_long=torch.LongTensor):\n",
    "    # Get four corner indicies\n",
    "    x0 = torch.floor(x).type(dtype_long)\n",
    "    x1 = x0 + 1\n",
    "    y0 = torch.floor(y).type(dtype_long)\n",
    "    y1 = y0 + 1\n",
    "    # Clamp within h, w boundries\n",
    "    x0 = torch.clamp(x0, 0, im.shape[1]-1)\n",
    "    x1 = torch.clamp(x1, 0, im.shape[1]-1)\n",
    "    y0 = torch.clamp(y0, 0, im.shape[0]-1)\n",
    "    y1 = torch.clamp(y1, 0, im.shape[0]-1)\n",
    "    # Get four corner pixel values\n",
    "    Ia = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x0, y0)])\n",
    "    Ib = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x0, y1)])\n",
    "    Ic = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x1, y0)])\n",
    "    Id = torch.cat([im[coord[0], coord[1], :].unsqueeze(0) for coord in zip(x1, y1)])\n",
    "    # Define matricies\n",
    "    scale = (1 / ( (x1-x0) * (y1-y0) ) ).flatten()\n",
    "    m1 = torch.cat([ torch.sub(x1, x), torch.sub(x, x0)], dim=1)\n",
    "    m2 = torch.stack([Ib, Ia, Id, Ic], dim=1).reshape(16,2,2,3).permute(1,0,2,3).reshape(2,-1)\n",
    "    m3 = torch.cat([ torch.sub(y1, y), torch.sub(y, y0) ], dim=1)\n",
    "    # Reshape for batch matmul\n",
    "    m3 = m3.reshape(16,1,2,1)\n",
    "    print(torch.matmul(m1, m2).reshape(16,2,1,3))\n",
    "    return scale[:,None] * torch.matmul( torch.matmul(m1, m2).permute(0,3,2,1), m3 ).flatten(start_dim=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 352,
   "id": "5c9cd260-4327-49fa-97b3-60737f93b155",
   "metadata": {},
   "outputs": [
    {
     "ename": "RuntimeError",
     "evalue": "shape '[16, 2, 1, 3]' is invalid for input of size 1536",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "\u001b[0;32m/tmp/ipykernel_63356/338345741.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mfast_interpolation_3cb\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mimage3c\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mx_b\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_b\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/tmp/ipykernel_63356/3401880313.py\u001b[0m in \u001b[0;36mfast_interpolation_3cb\u001b[0;34m(im, x, y, dtype, dtype_long)\u001b[0m\n\u001b[1;32m     22\u001b[0m     \u001b[0;31m# Reshape for batch matmul\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     23\u001b[0m     \u001b[0mm3\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mm3\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 24\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreshape\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m16\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     25\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mscale\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m*\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatmul\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mm1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm2\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpermute\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m2\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mm3\u001b[0m \u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mstart_dim\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: shape '[16, 2, 1, 3]' is invalid for input of size 1536"
     ]
    }
   ],
   "source": [
    "# use torch einsum\n",
    "fast_interpolation_3cb(image3c, x_b, y_b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "02415445-11a1-4bd6-b9b5-e5a6a00d43b2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pytorch_env",
   "language": "python",
   "name": "pytorch_env"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
